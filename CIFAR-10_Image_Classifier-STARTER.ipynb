{"cells":[{"cell_type":"markdown","metadata":{"id":"0yozxx9mCzUm"},"source":["# Introduction\n","\n","In this project, you will build a neural network of your own design to evaluate the CIFAR-10 dataset.\n","Our target accuracy is 70%, but any accuracy over 50% is a great start.\n","Some of the benchmark results on CIFAR-10 include:\n","\n","78.9% Accuracy | [Deep Belief Networks; Krizhevsky, 2010](https://www.cs.toronto.edu/~kriz/conv-cifar10-aug2010.pdf)\n","\n","90.6% Accuracy | [Maxout Networks; Goodfellow et al., 2013](https://arxiv.org/pdf/1302.4389.pdf)\n","\n","96.0% Accuracy | [Wide Residual Networks; Zagoruyko et al., 2016](https://arxiv.org/pdf/1605.07146.pdf)\n","\n","99.0% Accuracy | [GPipe; Huang et al., 2018](https://arxiv.org/pdf/1811.06965.pdf)\n","\n","98.5% Accuracy | [Rethinking Recurrent Neural Networks and other Improvements for ImageClassification; Nguyen et al., 2020](https://arxiv.org/pdf/2007.15161.pdf)\n","\n","Research with this dataset is ongoing. Notably, many of these networks are quite large and quite expensive to train.\n","\n","## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15172,"status":"ok","timestamp":1722411701824,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"RnsBLxX1CzUo"},"outputs":[],"source":["## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Rs77nBknCzUp"},"source":["## Load the Dataset\n","\n","Specify your transforms as a list first.\n","The transforms module is already loaded as `transforms`.\n","\n","CIFAR-10 is fortunately included in the torchvision module.\n","Then, you can create your dataset using the `CIFAR10` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar)).\n","Make sure to specify `download=True`!\n","\n","Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9888,"status":"ok","timestamp":1722411711700,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"CA35YY2ICzUq","outputId":"2f05b904-e65b-4277-d1f9-c48315e33a65"},"outputs":[],"source":["# Define transforms\n","## YOUR CODE HERE ##\n","train_transform = transforms.Compose([\n","    transforms.RandomRotation(30),\n","    transforms.RandomResizedCrop(32),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor()\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# Create training set and define training dataloader\n","## YOUR CODE HERE ##\n","train_data = torchvision.datasets.CIFAR10('CIFAR10/', download=True, train=True, transform=train_transform)\n","train_data, validation_data = torch.utils.data.random_split(train_data, [0.8, 0.2])\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n","validationloader = torch.utils.data.DataLoader(validation_data, batch_size=64, num_workers=4, pin_memory=True)\n","\n","# Create test set and define test dataloader\n","## YOUR CODE HERE ##\n","test_data = torchvision.datasets.CIFAR10('CIFAR10/', download=True, train=False, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64, num_workers=4, pin_memory=True)\n","\n","# The 10 classes in the dataset\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"id":"kZL-IbQPCzUq"},"source":["## Explore the Dataset\n","Using matplotlib, numpy, and torch, explore the dimensions of your data.\n","\n","You can view images using the `show5` function defined below – it takes a data loader as an argument.\n","Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n","Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n","If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1722411711700,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"0h989DRuCzUq"},"outputs":[],"source":["def show5(img_loader):\n","    dataiter = iter(img_loader)\n","\n","    batch = next(dataiter)\n","    labels = batch[1][0:5]\n","    images = batch[0][0:5]\n","    for i in range(5):\n","        print(classes[labels[i]])\n","\n","        image = images[i].numpy()\n","        plt.imshow(image.T)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5479,"status":"ok","timestamp":1722411717168,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"p2GkD4npCzUq","outputId":"7eed9221-8478-46c0-a84e-b2442fc0ba2d"},"outputs":[],"source":["# Explore data\n","## YOUR CODE HERE ##\n","show5(trainloader)\n","show5(validationloader)\n","show5(testloader)"]},{"cell_type":"markdown","metadata":{"id":"ScyhdgnnCzUq"},"source":["## Build your Neural Network\n","Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n","Feel free to construct a model of any architecture – feedforward, convolutional, or even something more advanced!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":595,"status":"ok","timestamp":1722411717749,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"tNjS0okQCzUq","outputId":"e688bc22-e494-4853-c706-f5874f245551"},"outputs":[],"source":["## YOUR CODE HERE ##\n","\n","class Classifier(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.fc1 = nn.Linear(3*32*32, 64)\n","    self.fc2 = nn.Linear(64, 32)\n","    self.fc3 = nn.Linear(32, 10)\n","\n","    self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, x):\n","    x = x.view(x.shape[0], -1)\n","\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.logsoftmax(self.fc3(x))\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"5D5knxymCzUq"},"source":["Specify a loss function and an optimizer, and instantiate the model.\n","\n","If you use a less common loss function, please note why you chose that loss function in a comment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1722411717749,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"ypKZ_MnhCzUr","outputId":"2fa9687a-c6da-47f8-c355-6c56b877515b"},"outputs":[],"source":["## YOUR CODE HERE ##\n","model = Classifier()\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9) # to avoid the local minima problem"]},{"cell_type":"markdown","metadata":{"id":"3HtsyzDVCzUr"},"source":["## Running your Neural Network\n","Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch.\n","Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n","\n","If you want to print your loss during each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":732935,"status":"error","timestamp":1722412450682,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"2INK9V63CzUr","outputId":"611c1ee2-0d3a-48c4-a98a-89f8f20df228"},"outputs":[],"source":["## YOUR CODE HERE ##\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","epochs = 60\n","steps = 0\n","print_every = 250\n","total_train_loss = 0\n","\n","train_losses = []\n","validation_losses = []\n","accuracies = []\n","\n","for epoch in range(epochs):\n","  for images, labels in trainloader:\n","    steps += 1\n","\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    optimizer.zero_grad()\n","    logps = model.forward(images)\n","    loss = criterion(logps, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_train_loss += loss.item()\n","\n","    if steps % print_every == 0:\n","      model.eval()\n","\n","      total_validation_loss = 0\n","      total_accuracy = 0\n","\n","      with torch.no_grad():\n","        for images, labels in validationloader:\n","          images = images.to(device)\n","          labels = labels.to(device)\n","          \n","          logps = model.forward(images)\n","          loss = criterion(logps, labels)\n","          total_validation_loss += loss.item()\n","\n","          ps = torch.exp(logps)\n","          top_p, top_class = ps.topk(1, dim=1)\n","          equality = top_class == labels.view(*top_class.shape)\n","          total_accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n","      \n","      train_loss = total_train_loss/print_every\n","      test_loss = total_validation_loss/len(testloader)\n","      accuracy = total_accuracy/len(testloader)\n","\n","      print(f\"Epoch {epoch+1}/{epochs}.. \"\n","                f\"Train loss: {train_loss:.4f}.. \"\n","                f\"Validation loss: {test_loss:.4f}.. \"\n","                f\"Validation Accuracy: {accuracy:.4f}\")\n","\n","      train_losses.append(train_loss)\n","      validation_losses.append(test_loss)\n","      accuracies.append(accuracy)\n","      total_train_loss = 0\n","      model.train()"]},{"cell_type":"markdown","metadata":{"id":"nYUYmcn2CzUr"},"source":["Plot the training loss (and validation loss/accuracy, if recorded)."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1722412450683,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"MvbiUVOcCzUr"},"outputs":[],"source":["## YOUR CODE HERE ##\n","%matplotlib inline\n","%config inlineBackend.figure_format='retina'\n","\n","import matplotlib.pyplot as plt\n","plt.plot(train_losses,label='Train loss')\n","plt.plot(validation_losses,label='Validation loss')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(accuracies,label='Validation accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7O047-6LCzUr"},"source":["## Testing your model\n","Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction.\n","\n","If your accuracy is over 70%, great work!\n","This is a hard task to exceed 70% on.\n","\n","If your accuracy is under 45%, you'll need to make improvements.\n","Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1722412450684,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"O0hLQa5gCzUr"},"outputs":[],"source":["## YOUR CODE HERE ##\n","accuracy = 0\n","model.eval()\n","with torch.no_grad():\n","  for images, labels in testloader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    logps = model.forward(images)\n","\n","    ps = torch.exp(logps)\n","    top_p, top_class = ps.topk(1, dim=1)\n","    equality = top_class == labels.view(*top_class.shape)\n","    accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n","model.train()\n","print(f\"Test accuracy: {accuracy/len(testloader):.4%}\")"]},{"cell_type":"markdown","metadata":{"id":"hu8R5ggACzUr"},"source":["## Saving your model\n","Using `torch.save`, save your model for future loading."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1722412450684,"user":{"displayName":"Đặng Huy Hoàng","userId":"09905509070890793598"},"user_tz":-420},"id":"XyneMiooCzUr"},"outputs":[],"source":["## YOUR CODE HERE ##\n","checkpoint = {'state_dict': model.state_dict(),\n","            'optimizer': optimizer,\n","            'criterion': criterion,\n","            'accuracies':accuracies,\n","            'train_losses':train_losses,\n","            'validation_losses': validation_losses,\n","            'model': model}\n","torch.save(checkpoint, 'checkpoint2.pth')"]},{"cell_type":"markdown","metadata":{"id":"PrUOG3cuCzUs"},"source":["## Make a Recommendation\n","\n","Based on your evaluation, what is your recommendation on whether to build or buy? Explain your reasoning below."]},{"cell_type":"markdown","metadata":{"id":"0mncmx0cCzUs"},"source":["\n","\n","**Double click this cell to modify it**\n","\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
